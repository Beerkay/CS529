{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  MLP Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Add one extra hidden layer \n",
    "2. Change the ReLU activations to sigmoid activations at all hidden layers\n",
    "3. Not change anything else (i.e., keep the softmax activation, etc.)\n",
    "4. Change the textual description of the neural network, its foward and backward passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pylab\n",
    "import numpy as np\n",
    "\n",
    "X, y = make_moons(n_samples=5000, random_state=42, noise=0.1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,test_size=0.3)\n",
    "\n",
    "pylab.scatter(X[:,0], X[:,1], c=y)\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create the Neural Network Weights and Initialize Them\n",
    "\n",
    "We first define:\n",
    "* the input layer (two coordinates)\n",
    "* number of hidden layers (we will use **two**)\n",
    "* the number of output neurons (number of classes, two in our case) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# There are only two features in the data X[:,0] and X[:,1]\n",
    "n_feature = 2\n",
    "\n",
    "# There are only two classes: 0 (purple) and 1 (yellow)\n",
    "n_class = 2\n",
    "\n",
    "def init_weights(n_hidden=100):\n",
    "    # Initialize weights with Standard Normal random variables\n",
    "    model = dict(\n",
    "        W1=np.random.randn(n_feature + 1, n_hidden),\n",
    "        \n",
    "        # The weights corresponding to the additional hidden layer. \n",
    "        W2=np.random.randn(n_hidden + 1, n_hidden),\n",
    "        \n",
    "        W3=np.random.randn(n_hidden + 1, n_class)\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Define the nonlinear activation function (will be used in the last layer)\n",
    "\n",
    "We will use the softmax function. \n",
    "\n",
    "$$\n",
    "\\text{softmax}(x_i) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}\n",
    "$$\n",
    "\n",
    "If there are only two classes, the softmax is equivalent to the logistic function (do the math to convince yourself).\n",
    "\n",
    "#### Python + Numpy tricks\n",
    "Numpy is *very* handy. If we give a vector $x$, np.exp($x$) returns a vector with all elements of $x$ exponentiated.\n",
    "\n",
    "If $y$ is a vector, $y$.sum() returns the sum of the elements in $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the sigmoid (logistic) activation function. \n",
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "        Inputs  : A tensor x.\n",
    "        Outputs : 1 / (1 + exp(-x)).\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Defines the softmax function. For two classes, this is equivalent to the logistic regression\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.exp(x).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Define the forward pass\n",
    "\n",
    "Here, we define how the neural network get an input $x$ and use the model paramters (weights) $W^{(1)}$, $W^{(2)}$ and $W^{(3)}$, and biases $b^{(1)}$, $b^{(2)}$ and $b^{(3)}$ to predict the class labels of the input.\n",
    "\n",
    "Forward Pass Equations. : \n",
    "\n",
    "**Input Layer to Hidden Layer 1**\n",
    "$$ z^{(1)} = x W^{(1)} + b^{(1)} $$\n",
    "$$ h^{(1)} = SIGMOID(z^{(1)}) $$\n",
    "\n",
    "**Hidden Layer 1 to Hidden Layer 2**\n",
    "$$ z^{(2)} = h^{(1)} W^{(2)} + b^{(2)} $$\n",
    "$$ h^{(2)} = SIGMOID(z^{(2)}) $$\n",
    "\n",
    "**Hidden Layer 2 to Output Layer**\n",
    "$$ z^{(3)} = h^{(2)} W^{(3)} + b^{(3)} $$\n",
    "$$ \\hat{y}  = SOFTMAX(z^{(3)}) $$\n",
    "\n",
    "ReLU Activation : \n",
    "$$\n",
    "\\text{ReLU}(z) = \\begin{cases} z & ,\\text{if }z \\geq 0 \\\\\n",
    "0 & ,\\text{if }z < 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Sigmoid Activation : \n",
    "$$\n",
    "f(x) = \\frac{1}{( 1 + e^{(-x)})}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# For a single example $x$\n",
    "def forward(x, model):\n",
    "    \n",
    "    ######### Layer 1 ##########\n",
    "    \n",
    "    x = np.append(x, 1)\n",
    "    \n",
    "    # Input times first layer matrix \n",
    "    z_1 = x @ model['W1']\n",
    "\n",
    "    # ReLU activation goes to hidden layer. (Comment out the ReLU activation part).\n",
    "    # h1 = z_1\n",
    "    # h1[z_1 < 0] = 0\n",
    "    \n",
    "    # Activation for the first hidden layer. \n",
    "    h1 = sigmoid(z_1)\n",
    "    \n",
    "    \n",
    "    ######### Layer 2 ##########\n",
    "    \n",
    "    # Incorporation of the bias unit in the output of the first layer.\n",
    "    h1 = np.append(h1, 1)\n",
    "    \n",
    "    # Output of the first hidden layer times second layer matrix.\n",
    "    z_2 = h1 @ model['W2']\n",
    "    \n",
    "    # ReLU activation goes to hidden layer. (Comment out the ReLU activation part).\n",
    "    # h2 = z_2\n",
    "    # h2[z_2 < 0] = 0\n",
    "    \n",
    "    # Activation for the first hidden layer. \n",
    "    h2 = sigmoid(z_2)\n",
    "    \n",
    "    ######### Layer 3 ##########\n",
    "    \n",
    "    # Incorporation of the bias unit in the output of the second layer. \n",
    "    h2 = np.append(h2, 1)\n",
    "    \n",
    "    # Output of the second hidden layer times third layer matrix.\n",
    "    z_3 = h2 @ model['W3']\n",
    "    \n",
    "    hat_y = softmax(z_3)\n",
    "\n",
    "    return h1, h2, hat_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Define backpropagation\n",
    "\n",
    "Now, we need to backpropagate the derivatives of each example\n",
    "\n",
    "The backpropagation function gets:\n",
    "* all input data $\\{x_i\\}_i$\n",
    "* corresponding hidden values of *all* training examples: $\\{h_i\\}_i$ (for all the hidden layers part of our network)\n",
    "* errors of each output neuron for *all* training examples: $\\{y_i - \\hat{y}_i\\}_i$ (this is a subtraction of two vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our score function of training example $i$ will be, which is the log likelihood of a one-hot enconding vector of the classes,\n",
    "$$\n",
    "L(i) = \\sum_j y_i(j) \\log \\hat{y}_i(j) ,\n",
    "$$\n",
    "where $y_i(j)$ is the element $j$ of the vector representing the one-hot enconding of the class of training example $i$ and $\\hat{y}_i(j)$ is the output of the $j$-th output neuron for training example $i$,\n",
    "$$\n",
    "\\hat{y}_i(j) = \\frac{\\exp(z^{(2)}(j))}{\\sum_k \\exp(z^{(2)}(k))}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The derivative of the loss with respect to $z_3$ will be a vector (that we will represent using the variables without the index $j$)\n",
    "$$\n",
    "\\frac{\\partial L(i)}{\\partial z^{(3)}} = (y_i(1) - \\hat{y}_i(1),\\ldots,y_i(\\text{n_class}) - \\hat{y}_i(\\text{n_class})) = y_i - \\hat{y}_i.\n",
    "$$\n",
    "**Note that we can get this derivative directly from the relative error `errs`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Other derivatives during the backpropation : \n",
    "\n",
    "It will compute the following derivatives for each training example:\n",
    "* The derivatives of the region between the output layer and the second hidden layer.\n",
    "$$\n",
    "\\frac{\\partial L(i)}{\\partial W^{(3)}} = \\frac{\\partial z^{(3)}(i)}{\\partial W^{(3)}}  \\frac{\\partial L(i)}{\\partial z^{(3)}} = h^{(2)^T}  (y_i - \\hat{y}_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L(i)}{\\partial b^{(3)}} = \\frac{\\partial z^{(3)}(i)}{\\partial b^{(3)}}  \\frac{\\partial L(i)}{\\partial z^{(3)}} =  (y_i - \\hat{y}_i),\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z^{(3)}(i)}{\\partial b^{(3)}} = 1.\n",
    "$$\n",
    "\n",
    "* The derivatives with respect to the hidden values of the hidden layer 2 are\n",
    "$$\n",
    "\\frac{\\partial L(i)}{\\partial h^{(2)}} = \\frac{\\partial z^{(3)}(i)}{\\partial h^{(2)}}  \\frac{\\partial L(i)}{\\partial z^{(3)}} =  W^{(3)} (y_i - \\hat{y}_i)\n",
    "$$\n",
    "\n",
    "* We need to keep track of this, because we will be backpropagating this to the previous layer(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We then backpropagate $\\partial L(i)/\\partial h^{(2)} $ to the previous layer (Hidden Layer 1). This will be needed in the final derivative calculations.\n",
    "\n",
    "The derivatives of the region between the second hidden layer and the first hidden layer.\n",
    "$$\n",
    "\\frac{\\partial L(i)}{\\partial W^{(2)}} = \\frac{\\partial z^{(2)}(i)}{\\partial W^{(2)}} \\frac{\\partial h^{(2)}(i)}{\\partial z^{(2)}} \\frac{\\partial L(i)}{\\partial h^{(2)}} = W^{(3)} (y_i - \\hat{y}_i) \\frac{\\partial h^{(2)}(i)}{\\partial z^{(2)}} h^{(1)},\n",
    "$$ \n",
    "\n",
    "$$\n",
    "\\frac{\\partial L(i)}{\\partial b^{(2)}} = \\frac{\\partial z^{(2)}(i)}{\\partial b^{(2)}} \\frac{\\partial h^{(2)}(i)}{\\partial z^{(2)}} \\frac{\\partial L(i)}{\\partial h^{(2)}} = W^{(3)} (y_i - \\hat{y}_i) \\frac{\\partial h^{(2)}(i)}{\\partial z^{(2)}},\n",
    "$$ \n",
    "\n",
    "$$\n",
    "\\frac{\\partial z^{(2)}(i)}{\\partial W^{(2)}} = h^{(1)},\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z^{(2)}(i)}{\\partial b^{(2)}} = 1,\n",
    "$$\n",
    "\n",
    "Derivative of the sigmoid function is as follows : \n",
    "$$\n",
    "\\frac{\\partial f(x)}{\\partial x} = f(x) \\times (1 - f(x)) \n",
    "$$\n",
    "\n",
    "* The derivatives with respect to the hidden values of the hidden layer 2 are\n",
    "$$\n",
    "\\frac{\\partial L(i)}{\\partial h^{(1)}} = \\frac{\\partial z^{(2)}}{\\partial h^{(1)}}  \\frac{\\partial L(i)}{\\partial h^{(2)}} \\frac{\\partial h^{(2)}}{\\partial z^{(2)}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial z^{(2)}}{\\partial h^{(1)}} = W^{(2)}\n",
    "$$\n",
    "\n",
    "* We need to keep track of this, because we will be backpropagating this to the previous layer(s).\n",
    "\n",
    "The derivatives of the region between the input layer and the first hidden layer.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L(i)}{\\partial W^{(1)}} = \\frac{\\partial z^{(1)}(i)}{\\partial W^{(1)}} \\frac{\\partial h^{(1)}(i)}{\\partial z^{(1)}} \\frac{\\partial L(i)}{\\partial h^{(1)}},\n",
    "$$ \n",
    "\n",
    "$$\n",
    "\\frac{\\partial z^{(1)}(i)}{\\partial W^{(1)}} = x_{i}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L(i)}{\\partial b^{(1)}} = \\frac{\\partial z^{(1)}(i)}{\\partial b^{(1)}} \\frac{\\partial h^{(1)}(i)}{\\partial z^{(1)}} \\frac{\\partial L(i)}{\\partial h^{(1)}},\n",
    "$$ \n",
    "\n",
    "$$\n",
    "\\frac{\\partial z^{(1)}(i)}{\\partial b^{(1)}} = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The final outputs are the derivatives of the parameters.\n",
    "\n",
    "<span style=\"color:blue\"> In the above, we have described the backpropagation algorithm *per training example*. \n",
    "The following python code will, as described earlier, give all examples as inputs. Thus, the input is a matrix whose rows are the vectors of each training example.</span>\n",
    "\n",
    "This function outputs \n",
    "$$\n",
    "\\text{d}W^{(1)} = \\frac{1}{N} \\sum_{i=1}^N \\frac{\\partial L(i)}{\\partial W^{(1)}},\n",
    "$$ \n",
    "$$\n",
    "\\text{d}b^{(1)} = \\frac{1}{N} \\sum_{i=1}^N \\frac{\\partial L(i)}{\\partial b^{(1)}},\n",
    "$$ \n",
    "$$\n",
    "\\text{d}W^{(2)} =  \\frac{1}{N} \\sum_{i=1}^N \\frac{\\partial L(i)}{\\partial W^{(2)}},\n",
    "$$\n",
    "$$\n",
    "\\text{d}b^{(2)} =  \\frac{1}{N} \\sum_{i=1}^N \\frac{\\partial L(i)}{\\partial b^{(2)}},\n",
    "$$\n",
    "$$\n",
    "\\text{d}W^{(3)} = \\frac{1}{N} \\sum_{i=1}^N \\frac{\\partial L(i)}{\\partial W^{(3)}},\n",
    "$$ \n",
    "$$\n",
    "\\text{d}b^{(3)} = \\frac{1}{N} \\sum_{i=1}^N \\frac{\\partial L(i)}{\\partial b^{(3)}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def backward(model, xs, hs1, hs2, errs):\n",
    "    \"\"\"\n",
    "        xs, hs1, hs2 and errs contain all information (input, hidden state 1, hidden state 2, error) of all \n",
    "        data in the minibatch.\n",
    "    \"\"\"\n",
    "    \n",
    "    ######## @@@@@@@@@@@@ Gradient of W3 @@@@@@@@@@@@ ########\n",
    "    \n",
    "    # errs is the gradients of output layer for the minibatch\n",
    "    dW3 = (hs2.T @ errs)/xs.shape[0]\n",
    "\n",
    "    # Get gradient of hidden layer 2.\n",
    "    dh2 = errs @ model['W3'].T\n",
    "    \n",
    "    # Derivative of the activation function.\n",
    "    # dh2[hs2 <= 0] = 0 (ReLU Activation derivative).\n",
    "    \n",
    "    # (Sigmoid Activation derivative).\n",
    "    dh2 = dh2 * sigmoid(hs2) * (1 - sigmoid(hs2))\n",
    "    \n",
    "    # The bias \"neuron\" is the constant 1, we don't need to backpropagate its gradient\n",
    "    # since it has no inputs, so we just remove its column from the gradient\n",
    "    dh2 = dh2[:, :-1]\n",
    "    \n",
    "    ######## @@@@@@@@@@@@ Gradient of W2 @@@@@@@@@@@@ ########\n",
    "\n",
    "    # Add the 1 to the input (h1), to compute the gradient of W2\n",
    "    # hs1 = np.hstack([hs1, np.ones((hs1.shape[0], 1))])\n",
    "    \n",
    "    # errs is the gradients of first hidden layer for the minibatch\n",
    "    dW2 = (hs1.T @ dh2)/xs.shape[0]\n",
    "    \n",
    "    dh1 = dh2 @ model['W2'].T\n",
    "    \n",
    "    # Derivative of the activation function.\n",
    "    # dh1[hs1 <= 0] = 0 (ReLU Activation derivative).\n",
    "    \n",
    "    # (Sigmoid Activation derivative).\n",
    "    dh1 = dh1 * sigmoid(hs1) * (1 - sigmoid(hs1))\n",
    "    \n",
    "    # The bias \"neuron\" is the constant 1, we don't need to backpropagate its gradient\n",
    "    # since it has no inputs, so we just remove its column from the gradient\n",
    "    dh1 = dh1[:, :-1]\n",
    "    \n",
    "    ######## @@@@@@@@@@@@ Gradient of W1 @@@@@@@@@@@@ ########\n",
    "    \n",
    "    # Add the 1 to the data, to compute the gradient of W1\n",
    "    xs = np.hstack([xs, np.ones((xs.shape[0], 1))])\n",
    "\n",
    "    dW1 = (xs.T @ dh1)/xs.shape[0]\n",
    "\n",
    "    return dict(W1=dW1, W2=dW2, W3=dW3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Perform the forward and backward procedures to get gradients\n",
    "\n",
    "For each input example $i$ in the training data, perform a forward pass and:\n",
    "* store all the hidden units of all the hidden layers associated with example $i$ (we have to store two vectors of hidden values)\n",
    "* store the gradient of the error of example $i$ with respect to the prediction.\n",
    "\n",
    "Once we have store all hidden layer values and all the derivatives of all examples, \n",
    "we will do the backard pass and return the derivatives of the error with respect to the paramters $W^{(1)}$, $b^{(1)}$, $W^{(2)}$, $b^{(2)}$, $W^{(3)}$ and $b^{(3)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def get_gradient(model, X_train, y_train):\n",
    "    xs, hs1, hs2, errs = [], [], [], []\n",
    "\n",
    "    for x, cls_idx in zip(X_train, y_train):\n",
    "        h1, h2, y_pred = forward(x, model)\n",
    "\n",
    "        # Create one-hot coding of true label\n",
    "        y_true = np.zeros(n_class)\n",
    "        y_true[int(cls_idx)] = 1.\n",
    "            \n",
    "        # Compute the gradient of output layer\n",
    "        err = y_true - y_pred\n",
    "\n",
    "        # Accumulate the informations of the examples\n",
    "        # x: input\n",
    "        # h: hidden state\n",
    "        # err: gradient of output layer\n",
    "        xs.append(x)\n",
    "        \n",
    "        hs1.append(h1)\n",
    "        # Store the hidden state activations for the hidden layers over the training examples.\n",
    "        hs2.append(h2)\n",
    "        \n",
    "        errs.append(err)\n",
    "\n",
    "    # Backprop using the informations we get from the current minibatch\n",
    "    return backward(model, np.array(xs), np.array(hs1), np.array(hs2), np.array(errs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Define one gradient ascent step\n",
    "\n",
    "We now perform a single gradient ascent step.\n",
    "\n",
    "Get the gradients and perform the following updates for $N$ training examples:\n",
    "$$\n",
    "W^{(1)} =W^{(1)} + \\epsilon \\frac{1}{N} \\sum_{i=1}^N \\frac{\\partial L(i)}{\\partial W^{(1)}},\n",
    "$$\n",
    "$$\n",
    "b^{(1)} =b^{(1)} + \\epsilon \\frac{1}{N} \\sum_{i=1}^N \\frac{\\partial L(i)}{\\partial b^{(1)}},\n",
    "$$\n",
    "$$\n",
    "W^{(2)} =W^{(2)} + \\epsilon \\frac{1}{N} \\sum_{i=1}^N \\frac{\\partial L(i)}{\\partial W^{(2)}},\n",
    "$$\n",
    "$$\n",
    "b^{(2)} =b^{(2)} + \\epsilon \\frac{1}{N} \\sum_{i=1}^N \\frac{\\partial L(i)}{\\partial b^{(2)}},\n",
    "$$\n",
    "$$\n",
    "W^{(3)} =W^{(3)} + \\epsilon \\frac{1}{N} \\sum_{i=1}^N \\frac{\\partial L(i)}{\\partial W^{(3)}},\n",
    "$$\n",
    "$$\n",
    "b^{(3)} =b^{(3)} + \\epsilon \\frac{1}{N} \\sum_{i=1}^N \\frac{\\partial L(i)}{\\partial b^{(3)}}.\n",
    "$$\n",
    "where $\\epsilon = 0.2$ in our example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_step(model, X_train, y_train, learning_rate = 0.2):\n",
    "    grad = get_gradient(model, X_train, y_train)\n",
    "    \n",
    "    # A redundant line, that is not really necessary. \n",
    "    # model = model.copy()\n",
    "\n",
    "    # Update every parameters in our networks (W1, W2 and W3) using their gradients\n",
    "    for layer in grad:\n",
    "        # Learning rate: 0.2\n",
    "        print (model[layer].shape)\n",
    "        print (grad[layer].shape)\n",
    "        model[layer] += learning_rate * grad[layer]\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Repeat gradient ascent a few more times..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_ascent(model, X_train, y_train, no_iter=10):\n",
    "    for iter in range(no_iter):\n",
    "        print('Iteration {}'.format(iter))\n",
    "\n",
    "        model = gradient_step(model, X_train, y_train)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Train the model\n",
    "\n",
    "We now train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "(3, 100)\n",
      "(3, 100)\n",
      "(101, 100)\n",
      "(101, 100)\n",
      "(101, 2)\n",
      "(101, 2)\n",
      "Iteration 1\n",
      "(3, 100)\n",
      "(3, 100)\n",
      "(101, 100)\n",
      "(101, 100)\n",
      "(101, 2)\n",
      "(101, 2)\n",
      "Iteration 2\n",
      "(3, 100)\n",
      "(3, 100)\n",
      "(101, 100)\n",
      "(101, 100)\n",
      "(101, 2)\n",
      "(101, 2)\n",
      "Iteration 3\n",
      "(3, 100)\n",
      "(3, 100)\n",
      "(101, 100)\n",
      "(101, 100)\n",
      "(101, 2)\n",
      "(101, 2)\n",
      "Iteration 4\n",
      "(3, 100)\n",
      "(3, 100)\n",
      "(101, 100)\n",
      "(101, 100)\n",
      "(101, 2)\n",
      "(101, 2)\n",
      "Iteration 5\n",
      "(3, 100)\n",
      "(3, 100)\n",
      "(101, 100)\n",
      "(101, 100)\n",
      "(101, 2)\n",
      "(101, 2)\n",
      "Iteration 6\n",
      "(3, 100)\n",
      "(3, 100)\n",
      "(101, 100)\n",
      "(101, 100)\n",
      "(101, 2)\n",
      "(101, 2)\n",
      "Iteration 7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f1b53f1e85f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_ascent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-e6e4e40e79df>\u001b[0m in \u001b[0;36mgradient_ascent\u001b[0;34m(model, X_train, y_train, no_iter)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-33dc3376c0ec>\u001b[0m in \u001b[0;36mgradient_step\u001b[0;34m(model, X_train, y_train, learning_rate)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgradient_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# A redundant line, that is not really necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# model = model.copy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-a9e13b733630>\u001b[0m in \u001b[0;36mget_gradient\u001b[0;34m(model, X_train, y_train)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Create one-hot coding of true label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-732ceec1fb5c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(x, model)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mz_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh2\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mhat_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhat_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-176605b71302>\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Defines the softmax function. For two classes, this is equivalent to the logistic regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     36\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     37\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "no_iter = 200\n",
    "\n",
    "# Set a random seed (for reproducibility of results). (A good practice).\n",
    "np.random.seed(47)\n",
    "\n",
    "# Reset model\n",
    "model = init_weights()\n",
    "\n",
    "# Train the model\n",
    "model = gradient_ascent(model, X_train, y_train, no_iter=no_iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Let's evaluate the model on test data\n",
    "Note that the output has two neurons for the two classes. Our prediction will chose the class corresponding to the \n",
    "largest output neuron value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.zeros_like(y_test)\n",
    "\n",
    "accuracy = 0\n",
    "\n",
    "for i, x in enumerate(X_test):\n",
    "    # Predict the distribution of label\n",
    "    _, _, prob = forward(x, model)\n",
    "    # Get label by picking the most probable one\n",
    "    y = np.argmax(prob)\n",
    "    y_pred[i] = y\n",
    "\n",
    "# Accuracy of predictions with the true labels and take the percentage\n",
    "# Because our dataset is balanced, measuring just the accuracy is OK\n",
    "accuracy = (y_pred == y_test).sum() / y_test.size\n",
    "print('Test accuracy after {} gradient steps: {}'.format(no_iter,accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Let's visually evaluate the model on the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.scatter(X_test[:,0], X_test[:,1], c=y_pred)\n",
    "pylab.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
